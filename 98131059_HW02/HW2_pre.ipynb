{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_HW02.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0AhGL2BM-MCP",
        "a5gQF7O8-mFj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AhGL2BM-MCP"
      },
      "source": [
        "# data utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwwZyz4S93r1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_dataset():\n",
        "    \n",
        "    df = pd.read_excel ('data.xlsx')\n",
        "    data = np.array(df)\n",
        "    y = data[:,0]\n",
        "    X = data[:,1:]\n",
        "    X = (data[:,1:] + 1) / 2    # all feature can be 0 or 0.5 or 1\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)  \n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcOwJysR-T3a"
      },
      "source": [
        "# SOM Class (using all features to train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BItQ8B8-Yl8"
      },
      "source": [
        "# first of all we load initial weights of map, for all experiments they are same\n",
        "X, y = load_dataset()\n",
        "n_features = X.shape[1]\n",
        "loaded_arr = np.loadtxt(\"weights_7-7.txt\") # u should load file based on ur map size, also u should set this map size in main\n",
        "initial_weights = loaded_arr.reshape( \n",
        "    loaded_arr.shape[0], loaded_arr.shape[1] // n_features, n_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8tVTqYk-b1f"
      },
      "source": [
        "# this for all feature in consideration\n",
        "\n",
        "random_weights = initial_weights \n",
        "\n",
        "\n",
        "# if u want to consider only a one of features u should run following code\n",
        "'''\n",
        "random_weights = initial_weights[:,8] # 0 means that we consider first column (check also X in main that features be same)\n",
        "random_weights = random_weights.reshape((random_weights.shape[0], random_weights.shape[1], 1))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mw1WGK9-hNl"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "class SOM:\n",
        "    def __init__(self, map_size, lr = 0.1):\n",
        "\n",
        "        self.map = random_weights\n",
        "        \n",
        "        self.lr0 = lr\n",
        "        self.lr = self.lr0\n",
        "        \n",
        "        self.R0 = map_size[0]//2\n",
        "        self.R = self.R0\n",
        "        \n",
        "    def train(self, X, y, T=1000, error_threshold=10**-20): \n",
        "        Js = []\n",
        "        # X is only features of dataset\n",
        "        # T is number of iterations\n",
        "        \n",
        "        for t in range(T):\n",
        "            prev_map = np.copy(self.map)\n",
        "            shuffle_ind = np.random.randint(low=0, high=len(X), size=len(X))  # a vector of random indices\n",
        "            for i in range(len(X)):\n",
        "                x = X[shuffle_ind[i],:]\n",
        "                x = np.asarray(x)\n",
        "                \n",
        "                winner = self.find_winner(x)    # winner = [1,4]\n",
        "                NS = self.get_NS(winner)\n",
        "                \n",
        "                self.update_weights(x, NS, len(X))\n",
        "                \n",
        "            self.lr = self.lr0 * (1 - t/T)\n",
        "            self.R = self.R0 * (1 - t/T)\n",
        "            \n",
        "            \n",
        "            Js.append(np.linalg.norm(prev_map - self.map))     # norm of changes\n",
        "            \n",
        "            if t % 10 == 0:\n",
        "                print('Iteration: %d, LR: %f, R: %f, J: %f' %(t, self.lr, self.R, Js[-1]))\n",
        "                # self.visualize(X, y)\n",
        "                \n",
        "            if Js[-1] < error_threshold:\n",
        "                print('Min changes')\n",
        "                break\n",
        "        \n",
        "        return Js\n",
        "            \n",
        "    def visualize(self, X, y):\n",
        "        self.scores = np.zeros(shape=(self.map.shape[0], self.map.shape[1], 3))  \n",
        "        # as we want to show scores in rgb format we choose third dimension as 3\n",
        "        # if you just want to cosider number u should cosider it equal to 1\n",
        "        for i in range(len(X)):\n",
        "            x = X[i, :]\n",
        "            x = np.asarray(x)\n",
        "            winner = self.find_winner(x)\n",
        "            iw, jw = winner[0], winner[1]\n",
        "            \n",
        "            if y[i] == -1:\n",
        "                self.scores[iw, jw] += np.asarray([1, 0, 0])\n",
        "            if y[i] == 1:\n",
        "                self.scores[iw, jw] += np.asarray([0, 0, 1])\n",
        "            if y[i] == 0:\n",
        "                self.scores[iw, jw] += np.asarray([0, 1, 0])\n",
        "                \n",
        "        self.scores = self.scores / np.mean(np.mean(self.scores))\n",
        "        \n",
        "        plt.imshow(self.scores)\n",
        "        plt.show()\n",
        "        \n",
        "    def find_winner(self, x):\n",
        "        rep_x = np.tile(x, [self.map.shape[0], self.map.shape[0], 1])\n",
        "        dists = np.sum((self.map - rep_x)**2, axis=2)   \n",
        "        winner = np.unravel_index(np.argmin(dists, axis=None), dists.shape)\n",
        "        \n",
        "        return winner\n",
        "    \n",
        "    def get_NS(self, winner):\n",
        "        NS = np.zeros(shape= (self.map.shape[0], self.map.shape[1]))\n",
        "        \n",
        "        iw, jw = winner[0], winner[1]\n",
        "        \n",
        "        '''\n",
        "        NS[iw, jw] = 1\n",
        "        # Plus-shape neighbourhood\n",
        "        for r in range(1, int(self.R)):\n",
        "            if iw - r >= 0:\n",
        "                NS[iw - r, jw] = 1/r\n",
        "            if iw + r < self.map.shape[0] - 1:\n",
        "                NS[iw + r , jw] = 1/r\n",
        "                \n",
        "            if jw - r > 0:\n",
        "                NS[iw , jw - r] = 1/r\n",
        "            if jw + r < self.map.shape[1] - 1:\n",
        "                NS[iw , jw + r] = 1/r\n",
        "        '''\n",
        "        R = int(self.R)\n",
        "        for ri in range(-R, R):\n",
        "            for rj in range(-R, R):\n",
        "                if (0 <= iw + ri < self.map.shape[0]) and  (0 <= jw + rj < self.map.shape[1]):   # baraye chek kardane inke noghte dar range dadeha bashad va daraghe dar morabae farzi gharar begirad\n",
        "                    NS[iw + ri, jw + rj] = 0 if np.sqrt(ri**2 + rj**2) > R else 1/ ( 1+ np.sqrt(ri**2 + rj**2))   # in noroun hamsaye dakhel dayereyi ke farz mikonim bashad, agar nabod nouron 0 va agar bod akse fasele(shoaa) + 1\n",
        "        \n",
        "\n",
        "                            \n",
        "        return NS\n",
        "    \n",
        "    def update_weights(self, x, n_strength, X_len):\n",
        "        NS = np.tile(n_strength, [self.map.shape[2],1,1]).transpose()\n",
        "        \n",
        "        rep_x = np.tile(x, [self.map.shape[0], self.map.shape[1], 1])\n",
        "        Delta = rep_x - self.map \n",
        "        \n",
        "        self.map = self.map + (self.lr/X_len) * np.multiply(NS, Delta)\n",
        "        \n",
        "    \n",
        "    def extract_feature(self, x): # here we give a data of n feature and take a matrix of size map as output (e.g, 9*9)\n",
        "        x = np.asarray(x)\n",
        "        rep_x = np.tile(x, [self.map.shape[0], self.map.shape[0], 1])\n",
        "        dists = np.sum((self.map - rep_x)**2, axis=2)\n",
        "        return 1/ (1 + dists)\n",
        "        \n",
        "if __name__==\"__main__\":\n",
        "    X, y = load_dataset()\n",
        "\n",
        "    '''\n",
        "    # if you want to train only on one of features, u should run following code otherwise dont run ]\n",
        "    X = X[:,8]  \n",
        "    X = np.asmatrix(X)\n",
        "    X = np.transpose(X)\n",
        "    '''\n",
        "\n",
        "    som_net = SOM(map_size = [7,7, X.shape[1]])\n",
        "    Js = som_net.train(X, y, T = 5000)\n",
        "    plt.plot(Js)\n",
        "    plt.show()\n",
        "    som_net.visualize(X, y)\n",
        "    x = X[0,:]\n",
        "    features = som_net.extract_feature(x)\n",
        "    plt.imshow(features)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccCKj66d_bXM"
      },
      "source": [
        "# creating new data by using som feature\n",
        "new_data_som = []\n",
        "for i in range(X.shape[0]):\n",
        "  x = X[i,:]\n",
        "  features = som_net.extract_feature(x)\n",
        "  tmp_data = features .flatten()\n",
        "  new_data_som.append(tmp_data)\n",
        "\n",
        "new_data_som = np.array(new_data_som)\n",
        "y_new_som = y\n",
        "y_new_som[y_new_som == -1] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5gQF7O8-mFj"
      },
      "source": [
        "# classification of data by MLP (Loss function: Cross entropy) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKGftB26-30t"
      },
      "source": [
        "## importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KLZfIXC-xJq"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD-z3cKr_E4u"
      },
      "source": [
        "## Spiliting data to train, test and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXCIMlgK_F7c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     new_data_som, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI2r_vx9_Kvv"
      },
      "source": [
        "## classification of data by MLP (Loss function: Cross entropy) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU6exVkM_LuF"
      },
      "source": [
        "# create model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
        "model.add(keras.layers.Dense(80, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytIi_B73_OYo"
      },
      "source": [
        "# Training model\n",
        "history = model.fit(X_train, y_train, batch_size=5, epochs= 30, validation_split= 0.18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EbfnTOh_QoV"
      },
      "source": [
        "# plot model accuracy and loss \n",
        "  # accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "  # loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzI9F6om_Trh"
      },
      "source": [
        "# evaluating\n",
        "test_loss, test_acc = model.evaluate( X_test, y_test, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjQ5Pg2j_V4Q"
      },
      "source": [
        "# Predicting labels\n",
        "predicted_values = model.predict(X_test)\n",
        "predicted_classes = np.where(predicted_values > 0.5, 1, 0)\n",
        "# visualize confusion matrix \n",
        "tn, fp, fn, tp = confusion_matrix(y_test, predicted_classes[:,0]).ravel()\n",
        "print('tn = ',tn , '\\t','fp = ',fp , '\\t','fn = ',fn , '\\t','tp = ',tp )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}