{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tdxje57xKwne",
        "dHelFgo-MLQB",
        "Ert32JtVJwQN",
        "Uj9RRAOALhyb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZCVRrrbLJWy"
      },
      "source": [
        "# install tensorflow 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iDtV8qbLdRt"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZwD19wHLhzf"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdxje57xKwne"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N27-JoihZ7oD"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHelFgo-MLQB"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4YaRsfiMFoa"
      },
      "source": [
        "                  1-1 Loading data set_1.csv And check if it's linearly separable or not...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV8QrHOzMl2z"
      },
      "source": [
        "set_1 = pd.read_csv(\"set_1.csv\")\n",
        "set_1 = np.array(set_1)\n",
        "plt.scatter(set_1[:, 0], set_1[:, 1], c=set_1[:, 2], s=50, cmap='plasma')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMXeb7hDlcax"
      },
      "source": [
        "                            1-2- Preprocessing data (scale data matrix to the [0, 1] range)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HQy8OPnsgH"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Processed_set_1 = min_max_scaler.fit_transform(set_1[:,0:2])\n",
        "plt.scatter(Processed_set_1[:, 0], Processed_set_1[:, 1], c=set_1[:, 2], s=50, cmap='plasma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvdgft5dvsrf"
      },
      "source": [
        "                      1-3- Split Processed_set_1 to Test_data and Train_data and for that we randomly choose 10% of data as Test_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDE9yp3TwGgy"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     Processed_set_1, set_1[:, 2], test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6-YZp5ojKhy"
      },
      "source": [
        "                        2- classification of data by MLP (Loss function: Cross entropy) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQZIS4ojvuj"
      },
      "source": [
        "# create model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=(2,)))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23HY8EkM5sSe"
      },
      "source": [
        "# Training model\n",
        "history = model.fit(X_train, y_train, batch_size=5, epochs= 100, validation_split= 0.18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPy6N8XAAY5"
      },
      "source": [
        "# plot model accuracy and loss \n",
        "  # accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy (Number of neurons = 8)')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "  # loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss (Number of neurons = 8)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITReVZh8Qofu"
      },
      "source": [
        "# evaluating\n",
        "test_loss, test_acc = model.evaluate( X_test, y_test, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73X6jgbG6fXq"
      },
      "source": [
        "# Predicting labels\n",
        "predicted_values = model.predict(X_test)\n",
        "predicted_classes = np.where(predicted_values > 0.5, 1, 0)\n",
        "# visualize confusion matrix \n",
        "tn, fp, fn, tp = confusion_matrix(y_test, predicted_classes[:,0]).ravel()\n",
        "print('tn = ',tn , '\\t','fp = ',fp , '\\t','fn = ',fn , '\\t','tp = ',tp )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ert32JtVJwQN"
      },
      "source": [
        "## Part 2 (section 1 and 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngKlsjRaJ9tG"
      },
      "source": [
        "                2-1 Loading data set_2.csv And check if it's linearly separable or not..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do6CdoHiJ4g-"
      },
      "source": [
        "set_2 = pd.read_csv(\"set_2.csv\")\n",
        "set_2 = np.array(set_2)\n",
        "plt.scatter(set_2[:, 0], set_2[:, 1], c=set_2[:, 2], s=50, cmap='plasma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mSYKHU4c8M"
      },
      "source": [
        "                      2-2- Preprocessing data (scale data matrix to the [0, 1] range)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXNzQxdR4jF3"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Processed_set_2 = min_max_scaler.fit_transform(set_2[:,0:2])\n",
        "plt.scatter(Processed_set_2[:, 0], Processed_set_2[:, 1], c=set_2[:, 2], s=50, cmap='plasma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4xb6n_m6KSy"
      },
      "source": [
        "              2-3- Split Processed_set_2 to Test_data and Train_data and for that we randomly choose 10% of data as Test_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91xugZO6G45"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     Processed_set_2, set_2[:, 2], test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAKvH4vM6aXq"
      },
      "source": [
        "           2- classification of data by MLP (Loss function: Cross entropy) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p41nZ77x6i02"
      },
      "source": [
        "# create model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=(2,)))\n",
        "model.add(keras.layers.Dense(14, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtKpw0l66qn4"
      },
      "source": [
        "# Training model\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs= 100, validation_split= 0.18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wlddfiO67My"
      },
      "source": [
        "# plot model accuracy and loss \n",
        "  # accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy (Number of neurons = 14)')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "  # loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss (Number of neurons = 14)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny8HX-sj6_Yj"
      },
      "source": [
        "# evaluating\n",
        "test_loss, test_acc = model.evaluate( X_test, y_test, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkUs8PvO7Ch2"
      },
      "source": [
        "# Predicting labels\n",
        "predicted_values = model.predict(X_test)\n",
        "predicted_classes = np.where(predicted_values > 0.5, 1, 0)\n",
        "# visualize confusion matrix \n",
        "tn, fp, fn, tp = confusion_matrix(y_test, predicted_classes[:,0]).ravel()\n",
        "print('tn = ',tn , '\\t','fp = ',fp , '\\t','fn = ',fn , '\\t','tp = ',tp )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9RRAOALhyb"
      },
      "source": [
        "## Part2 (section 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsN31UA_YiOW"
      },
      "source": [
        "        Loading data set_3.csv And check if it's linearly separable or not..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16aVKzxwYeUj"
      },
      "source": [
        "set_3 = pd.read_csv(\"set_3.csv\")\n",
        "set_3 = np.array(set_3)\n",
        "plt.scatter(set_3[:, 0], set_3[:, 1], c=set_3[:, 2], s=50, cmap='plasma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GATx1SWOYtyd"
      },
      "source": [
        "              Preprocessing data (scale data matrix to the [0, 1] range)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvJoAvULYwKF"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Processed_set_3 = min_max_scaler.fit_transform(set_3[:,0:2])\n",
        "plt.scatter(Processed_set_3[:, 0], Processed_set_3[:, 1], c=set_3[:, 2], s=50, cmap='plasma')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSfJne65Y7L9"
      },
      "source": [
        "          Split Processed_set_3 to Test_data and Train_data and for that we randomly choose 10% of data as Test_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSruhS-IZAvT"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     Processed_set_3, set_3[:, 2], test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs2yElUdZRJ-"
      },
      "source": [
        "          classification of data by MLP (Loss function: Cross entropy) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO0qS9jPZVpe"
      },
      "source": [
        "# create model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=(2,)))\n",
        "model.add(keras.layers.Dense(14, activation='relu'))\n",
        "model.add(keras.layers.Dense(14, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.007), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEde32MWaovw"
      },
      "source": [
        "# Training model\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs= 250, validation_split= 0.18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIzAMkDYapaN"
      },
      "source": [
        "# plot model accuracy and loss \n",
        "  # accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy (Number of neurons = 8)')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "  # loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss (Number of neurons = 8)')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYetln1gaviD"
      },
      "source": [
        "test_loss, test_acc = model.evaluate( X_test, y_test, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzbcbILpaxv2"
      },
      "source": [
        "# Predicting labels\n",
        "predicted_values = model.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNjx_Pbhm-8X"
      },
      "source": [
        "## Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B7139MWnDsy"
      },
      "source": [
        "        loading data set_4.csv (as 4th column of it has nan values we impute it using KNNImputer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DovDt_bKnJNY"
      },
      "source": [
        "set_4 = pd.read_csv(\"set_4.csv\")\n",
        "set_4 = np.array(set_4)\n",
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "set_4 = imputer.fit_transform(set_4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWQX940BwqV8"
      },
      "source": [
        "              Preprocessing data (scale data matrix to the [0, 1] range)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdJ8bPkYwvBt"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Processed_set_4 = min_max_scaler.fit_transform(set_4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1tNi-tRbfEJ"
      },
      "source": [
        "              Plot figure for each function values Z_1 and Z_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5YoGWP3w52L"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(Processed_set_4[:, 0], Processed_set_4[:, 1], Processed_set_4[:, 2], c='r', marker='o')\n",
        "ax.set_xlabel('X Label')\n",
        "ax.set_ylabel('Y Label')\n",
        "ax.set_zlabel('Z_1 Label')\n",
        "fig.suptitle('Z_1 function', fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BitFqxuaLdM"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(Processed_set_4[:, 0], Processed_set_4[:, 1], Processed_set_4[:, 3], c='r', marker='o')\n",
        "ax.set_xlabel('X Label')\n",
        "ax.set_ylabel('Y Label')\n",
        "ax.set_zlabel('Z_2 Label')\n",
        "fig.suptitle('Z_2 function', fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkZcyMJ2djwX"
      },
      "source": [
        "                1-3- Split Processed_set_1 to Test_data and Train_data and for that we randomly choose 10% of data as Test_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEOqOsL2di7C"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     Processed_set_4[:,0:2], Processed_set_4[:,2:4], test_size=0.1, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4PeLcCXbn1V"
      },
      "source": [
        "    ******  Creating model **********"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q4Up3W4bwAe",
        "outputId": "413f03f6-5742-42f0-a455-a7eed3d9d926"
      },
      "source": [
        "# create model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.Input(shape=(2,)))\n",
        "model.add(keras.layers.Dense(14, activation='relu'))\n",
        "model.add(keras.layers.Dense(14, activation='relu'))\n",
        "model.add(keras.layers.Dense(2))\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 14)                42        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 14)                210       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 30        \n",
            "=================================================================\n",
            "Total params: 282\n",
            "Trainable params: 282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDN8z-6-IBg6",
        "outputId": "e834ccbb-27f2-4871-a05a-febc8af9a661"
      },
      "source": [
        "# Training model\n",
        "history = model.fit(X_train, y_train, batch_size=10, epochs= 150, validation_split= 0.18)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6998 - val_loss: 0.4520\n",
            "Epoch 2/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.2587\n",
            "Epoch 3/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2069 - val_loss: 0.1371\n",
            "Epoch 4/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.0730\n",
            "Epoch 5/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0665 - val_loss: 0.0563\n",
            "Epoch 6/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0526\n",
            "Epoch 7/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 0.0504\n",
            "Epoch 8/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0488\n",
            "Epoch 9/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0477\n",
            "Epoch 10/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.0467\n",
            "Epoch 11/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0450\n",
            "Epoch 12/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0436\n",
            "Epoch 13/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0410\n",
            "Epoch 14/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0399\n",
            "Epoch 15/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0400\n",
            "Epoch 16/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0369\n",
            "Epoch 17/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0350\n",
            "Epoch 18/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0337\n",
            "Epoch 19/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.0318\n",
            "Epoch 20/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0310\n",
            "Epoch 21/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0305 - val_loss: 0.0293\n",
            "Epoch 22/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.0283\n",
            "Epoch 23/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0263\n",
            "Epoch 24/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0249\n",
            "Epoch 25/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0238\n",
            "Epoch 26/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0245\n",
            "Epoch 27/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0226\n",
            "Epoch 28/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0209\n",
            "Epoch 29/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0199\n",
            "Epoch 30/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0192\n",
            "Epoch 31/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0189\n",
            "Epoch 32/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0185\n",
            "Epoch 33/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0177\n",
            "Epoch 34/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0170\n",
            "Epoch 35/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0167\n",
            "Epoch 36/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0161\n",
            "Epoch 37/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0159\n",
            "Epoch 38/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0167\n",
            "Epoch 39/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0157\n",
            "Epoch 40/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0157\n",
            "Epoch 41/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0152\n",
            "Epoch 42/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 43/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0148\n",
            "Epoch 44/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0148\n",
            "Epoch 45/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0149\n",
            "Epoch 46/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0141\n",
            "Epoch 47/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0145\n",
            "Epoch 48/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0139\n",
            "Epoch 49/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0131\n",
            "Epoch 50/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0126\n",
            "Epoch 51/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0126\n",
            "Epoch 52/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0116\n",
            "Epoch 53/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0121\n",
            "Epoch 54/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0110\n",
            "Epoch 55/150\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0115\n",
            "Epoch 56/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0107\n",
            "Epoch 57/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0108\n",
            "Epoch 58/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0100\n",
            "Epoch 59/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0100\n",
            "Epoch 60/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0102\n",
            "Epoch 61/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0097\n",
            "Epoch 62/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0099\n",
            "Epoch 63/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0103\n",
            "Epoch 64/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0097\n",
            "Epoch 65/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0094\n",
            "Epoch 66/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0100\n",
            "Epoch 67/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0094\n",
            "Epoch 68/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0091\n",
            "Epoch 69/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0091\n",
            "Epoch 70/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0093\n",
            "Epoch 71/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0092\n",
            "Epoch 72/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0091\n",
            "Epoch 73/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0088\n",
            "Epoch 74/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0092\n",
            "Epoch 75/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0093\n",
            "Epoch 76/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0087\n",
            "Epoch 77/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0091\n",
            "Epoch 78/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
            "Epoch 79/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0090\n",
            "Epoch 80/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0086\n",
            "Epoch 81/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0085\n",
            "Epoch 82/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0083\n",
            "Epoch 83/150\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0084\n",
            "Epoch 84/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0083\n",
            "Epoch 85/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0086\n",
            "Epoch 86/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0084\n",
            "Epoch 87/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0083\n",
            "Epoch 88/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0082\n",
            "Epoch 89/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0081\n",
            "Epoch 90/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0079\n",
            "Epoch 91/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0081\n",
            "Epoch 92/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0081\n",
            "Epoch 93/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0080\n",
            "Epoch 94/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0089\n",
            "Epoch 95/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0094\n",
            "Epoch 96/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0080\n",
            "Epoch 97/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0080\n",
            "Epoch 98/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0079\n",
            "Epoch 99/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0080\n",
            "Epoch 100/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0078\n",
            "Epoch 101/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0080\n",
            "Epoch 102/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0089\n",
            "Epoch 103/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0078\n",
            "Epoch 104/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0078\n",
            "Epoch 105/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0079\n",
            "Epoch 106/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0077\n",
            "Epoch 107/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0080\n",
            "Epoch 108/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0076\n",
            "Epoch 109/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0078\n",
            "Epoch 110/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0078\n",
            "Epoch 111/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0075\n",
            "Epoch 112/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0080\n",
            "Epoch 113/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0075\n",
            "Epoch 114/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0076\n",
            "Epoch 115/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0076\n",
            "Epoch 116/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0077\n",
            "Epoch 117/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0075\n",
            "Epoch 118/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0075\n",
            "Epoch 119/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0077\n",
            "Epoch 120/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0072\n",
            "Epoch 121/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0074\n",
            "Epoch 122/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0073\n",
            "Epoch 123/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0080\n",
            "Epoch 124/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0075\n",
            "Epoch 125/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0077\n",
            "Epoch 126/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0078\n",
            "Epoch 127/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0074\n",
            "Epoch 128/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0075\n",
            "Epoch 129/150\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0075\n",
            "Epoch 130/150\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0077\n",
            "Epoch 131/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0076\n",
            "Epoch 132/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0078\n",
            "Epoch 133/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0073\n",
            "Epoch 134/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0082\n",
            "Epoch 135/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0073\n",
            "Epoch 136/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0071\n",
            "Epoch 137/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0075\n",
            "Epoch 138/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0071\n",
            "Epoch 139/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0073\n",
            "Epoch 140/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0070\n",
            "Epoch 141/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0079\n",
            "Epoch 142/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0072\n",
            "Epoch 143/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0072\n",
            "Epoch 144/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0072\n",
            "Epoch 145/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0074\n",
            "Epoch 146/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0077\n",
            "Epoch 147/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0071\n",
            "Epoch 148/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0072\n",
            "Epoch 149/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0069\n",
            "Epoch 150/150\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Y9tHkDAEXv9T",
        "outputId": "8d7bdce2-a500-4ca6-c89e-c667e7cd1338"
      },
      "source": [
        "# plot model loss \n",
        "\n",
        "  # loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4aOT9yqX-ze",
        "outputId": "fb14e1e2-a020-41b2-baaf-43aaa8323ea9"
      },
      "source": [
        "# Predicting labels\n",
        "predicted_values = model.predict(X_test)\n",
        "MSE_error = mean_squared_error(y_test,predicted_values) \n",
        "print(MSE_error)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003763308287664689\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}